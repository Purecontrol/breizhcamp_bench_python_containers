---
marp: true
theme: gaia

style: |
  img[alt~="center"] {
    display: block;
    margin: 0 auto;
  }
  section.center table {
    margin-left: auto;
    margin-right: auto;
  }
  section {
    font-size: 32px;
  }
  section.lead h1 {
    font-size: 100px;
  }

---

<!-- _paginate: skip -->


<!-- _class: lead -->
# Conteneurisation de Python
Chute de performances et investigations

<!--
_footer: "S√©bastien Baguet, Gaston Gary, Luc Sorel-Giffo - BreizhCamp - 27 juin 2025"
 -->

<script type="module">
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
  mermaid.initialize({ startOnLoad: true });
</script>

---

<!-- paginate: true -->

## Qui sommes-nous ?

* S√©bastien Baguet : devOps [Purecontrol](https://www.purecontrol.com/)
* Gaston Gary : dev [Purecontrol](https://www.purecontrol.com/)
* Luc Sorel-Giffo : lead dev [See you sun](https://seeyousun.fr/)
  - ex-Purecontrol ü´∂
  - co-animation [Python Rennes](https://www.meetup.com/fr-FR/python-rennes/) üîî
  - [@lucsorelgiffo@floss.social](https://floss.social/@lucsorelgiffo)

---

### S√©bastien Baguet

- **Infra lead** chez **Purecontrol**.
- sp√©cialis√© dans **l‚Äôinfrastructure open source**, **l‚Äôautomatisation** et la **scalabilit√©** des syst√®mes.
- Ancien responsable infrastructure chez **ARIADNEXT by IDNow**.
- **Direction des projets R&D** en Big Data et en machine learning.
- Expertises en **bas niveau** (embarqu√©, √©lectronique, r√©paration), aux applicatifs **Linux**, en passant par le **kernel**. 
- Int√©r√™t pour **l‚Äôimpact environnemental** des technologies.

---

### Gaston Gary 

- d√©veloppeur Python depuis 3 ans chez **Purecontrol**
- Responsable r√©cup√©ration de **donn√©es externes** en tout genre: *M√©teo, puissances actives, relev√©s manuels d'exploitants ...*
- interconnexions √† des APIs
- Maintenance d'un des services de calcul

---
### Purecontrol

![width:1000px](media/fonctionnement_Purecontrol_sch√©ma_FR.png)

<!-- Purecontrol est une soci√©t√© Rennaise, qui propose une solution de contr√¥le-commande bas√©e sur l‚Äôintelligence artificielle ; On pilote en temps r√©el les proc√©d√©s industriels li√©s √† l‚Äôeau et √† l‚Äô√©nergie pour r√©duire simultan√©ment la consommation, les co√ªts d‚Äôexploitation et les √©missions de CO‚ÇÇ. -->

---

## Applicatif m√©tier local-processing

(titre alternatif : Une antiquit√© bien dynamique)

- traitement et agr√©gation de **s√©ries temporelles**
- donn√©es synth√©tiques utilis√©es par d'autres briques m√©tier
- **50 000+ t√¢ches par minute**
- en temps r√©el
- imp√©ratif : **ne pas accumuler de retard**

---

![](media/archi.drawio.svg)

---

- **MainService**
  - **Thread**: soumission des t√¢ches √† ProcessPoolexecutor 
  - **boucle infinie**
    - monitoring
    - update tasks output status

- **Worker**
  - traitement **unitaire** d'une tache
  - **r√©cup√©ration** des donn√©es temporelles en entr√©e
  - **transformation**
  - **√©criture** de la s√©rie temporelle en output
<!-- 
-> parall√©lisme +++, IO r√©seau ++, CPU + (traitement des donn√©es) -->
---

### D√©ploiement old school

- interpr√©teur python de la VM
- git pull (√† la main en SSH)
- installation des d√©pendances sans **.venv/**
- red√©marrage ü§û

![bg right](media/vm-museum.png)

---

### Conteneurisation Docker

```dockerfile
ARG PYTHON_VERSION
FROM python:{PYTHON_VERSION}-slim
# installation des d√©pendances
# copie des sources
# lancement de l'application
...
```

Avantages classiques d'une image :
- isolation et maitrise du binaire python + d√©pendances + code source
- ex√©cution iso dev / tests / prod
- d√©ploiement : rapide, automatisable, serein

On en profite pour passer de 3.8 √† 3.12 üòÅ

---

### Oui mais... perte de performance de 30% ! 

![bg right](media/futur-c-etait-mieux-avant.jpg)

- **diminution** du nombre de t√¢ches calcul√©es chaque minute de **30%**
- accumulation rapide de **retard**
- optimisation d√©grad√©e des pilotages

---

### ü§î Est-ce l'effet de :

- la conteneurisation et l'allocation de ressources (CPU / RAM, overhead r√©seau) ?
* la dockerisation (comportement des binaires) ?
* la mont√©e de version de Python ?

---

## Quels sont les points d'optimisation d'un service num√©rique (Python) ?

(Luc : j'enl√®verais bien les 3 puces pour laisser la salle r√©pondre - on peut avoir des bonnes surprises - et garder le suspense sur l'optimisation du runtime)

- algorithmie
- architecture
- optimisation du runtime

---

### Profilage

- Cprofile + kcachegrind
- pyinstrument
- py-spy
- voir [Fantastic bits and where to find them : benchmark et profilage - Michel Caradec](https://www.youtube.com/watch?v=eY5k9GcHRVM) (Python Rennes, 5 d√©cembre 2024)

Dans notre cas, la perte de performance √©tait dilu√©e dans tout le code üòï

<!-- Utiliser un profiler comme `kcachegrind` sur les r√©sultats de Cprofile.

Pour visualiser :

- Fonctions les plus co√ªteuses
- Appels imbriqu√©s
- Consommation CPU par bloc de code

En comparant avant et apr√®s, cela pourrait permettre d'identifier un endroit ou l'on passe plus de temps, responsable d'une perte de performance.

```python
python -m cProfile -o prof.out my_app.py && pyprof2calltree -i prof.out -o callgrind.out && kcachegrind callgrind.out
``` -->

---

### Algorithmie - 1

```python
cursor.execute(t"SELECT * FROM tasks LIMIT 100")
tasks = []
for record in cursor: # allers-retours entre l'interpr√©tation et l'ex√©cution
  tasks.append(Task.from_db_record(record))
execute_tasks(tasks)
```

```python
tasks = [
  Task.from_db_record(record)
  for record in cursor
] # le corps de la compr√©hension est ex√©cut√© "d'un coup"
```

```python
execute_tasks(
  Task.from_db_record(record) for record in cursor
) # g√©n√©rateur streamant les t√¢ches
```

---

### Algorithmie - 2

- Python est un langage interpr√©t√© üêå
* facilite l'encapsulation de binaires pour les traitements CPU ‚ö°
  - numpy, pandas, polars
  - Tensorflow, pytorch, jax

---

### Architecture

- multithreading ou asyncio pour parall√©liser les op√©rations IO
  * ‚ö†Ô∏è au `global interpreter lock`
  * d√©sactivable dans la 3.14
* multiprocessing pour les op√©rations CPU
* tenir compte des co√ªts de cr√©ation des IO (connexions bdd, threads, process) : utiliser des pools

---

### Optimisation de l'ex√©cution - 1

```python
def transfer_money(amount: float, account):
  """ Adds a positive amount of money to the given account """
  assert is_a_valid_amount(amount)
  account.add(amount)
```

`python -O mon_script.py` supprime (voir la doc [cmdoption-O](https://docs.python.org/3/using/cmdline.html#cmdoption-O)) :
  - `-O` : les assertions, les blocs `if __debug__:`
  - `-OO` : les docstrings aussi

<!-- -> √©viter d'exprimer les v√©rifications m√©tier avec des `assert` -->

---

### Optimisation de l'ex√©cution - 2

üß™ Just-in-time compiler (voir [whatsnew313-jit-compiler](https://docs.python.org/3/whatsnew/3.13.html#whatsnew313-jit-compiler)) :
- modification du bytecode au fil de l'ex√©cution du programme
* additionner des entiers `!=` additionner des d√©cimaux
* üîé l'interpr√©teur doit avoir √©t√© compil√© avec cette option d'ex√©cution

---

### Optimisation du runtime python

Diff√©rentes optimisations durant les phases de compilation :

![center](./media/optimizations.drawio.svg)

Pour voir les options de compilation du runtime :

```sh
python3 -m sysconfig | grep CONFIG_ARGS
```

(voir [docs.python.org/3/using/configure.html](https://docs.python.org/3/using/configure.html#performance-options))

<!-- Seb
Compiler level optimisation

-O3 -> va optimiser fichier par fichier
-march=native -> S√©l√©ction de l'architecture courante comme cible
/!\ pas compatible avec un CPU qui n'aurait pas les instructions
Voir ici pour les subset https://gcc.gnu.org/onlinedocs/gcc/x86-Options.html

Profile Guided optimization
Compilation instrument√© -> Execution -> Recompilation optimis√©

Inlining, r√©organisation des blocs, optimisation des boucles, etc.

Link Time Optimization
Optimisation multi fichier .o

Analyse statique du programme entier

Post Link Optimization
Compilation normale -> Profilage (optionnel) -> Optimisation du binaire

R√©arrangement des fonctions/blocs (layout), ICF, optimisation des tables de saut, etc.
Optimisation cache
-->

---

<!-- 
### Comparaison de Dockerfiles officiels

- https://hub.docker.com/_/python/
  - https://github.com/docker-library/python/blob/14b61451ec7c172cf1d43d8e7859335459fcd344/3.11/slim-bookworm/Dockerfile#L72-L95

---

### Installation personnalis√©e avec pyenv LUC

voir :
- https://github.com/pyenv/pyenv/blob/master/plugins/python-build/README.md#special-environment-variables : CONFIGURE_OPTS
- https://github.com/pyenv/pyenv/blob/master/plugins/python-build/README.md#building-for-maximum-performance : --enable-optimizations

--- -->

### Attention aux options de compilation

Si les flags de compilation √©nonc√©s plus haut peuvent sembler optimaux,
Il y a  tout de m√™me quelques point important √† garder en t√™te ...

---

###  ils introduisent des **d√©pendances invisibles** √† l‚Äôarchitecture CPU

par exemple pour -march=native
- On **compile** l‚Äôinterpr√©teur Python **sp√©cifiquement** pour l‚Äôarchitecture du **CPU**.
- R√©sultat : l‚Äôimage **ne fonctionne plus** si on la lance sur une autre architecture (ex: `build` sur AMD ‚Üí `run` sur INTEL)

Il est donc **crucial** d‚Äôavoir la **m√™me architecture CPU** entre le `build` et le `run`

Sinon ‚ûú crash, `illegal instruction`.


<!-- 
- Nous l'avons d√©couvert √† la dur, notre runner gitlab √©tait h√©berg√© sur un noeud proxmox sous cpu **Intel Xeon Platinium**, alors que notre **vm de Production** √©tait sur un noeud proxmox sous cpu **AMD EPYC**. -->

---

## Benchmark des binaires python via des conteneurs

- applicatif "test" (architecture et op√©rations similaires √† l'application) tournant 30 minutes
- temps de cr√©ation & taille de chaque image Docker (7 images)
- m√©triques "syst√®me" : consommations CPU & RAM
- m√©triques m√©tier :  nb de t√¢ches r√©alis√©es
- m√©triques hybrides : CPU / t√¢che, RAM / t√¢che

---

### Collecte des m√©triques syst√®me

<div class="mermaid">
  flowchart LR
    benchmark -..->| üîé CPU, RAM | cAdvisor
    subgraph monitoring
      cAdvisor -..->| üíæ / 5s | prometheus
      prometheus -..->| üìä üó† | grafana
    end
</div>

- [cAdvisor](https://github.com/google/cadvisor) : suit les ressources syst√®me consomm√©es par les conteneurs
- [prometheus](https://prometheus.io/) : collecte et persiste des m√©triques expos√©es par des endpoints (t√©l√©m√©trie)
- [grafana](https://grafana.com/grafana/dashboards/) : agr√©gation et visualisation temps r√©el

---

### Runtimes python des images test√©es

<!-- style: table{font-size:.55em} -->

| Image | `--enable-optimizations` | `--with-lto`  | `-march = native` | `-mtune = native`| `--enable-bolt` | **Compilateur** |
|--|:--:|:--:|:--:|:--:|:--:|:--:|
| **debian**             | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | GCC |
| python **official**    | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | GCC |
| **pyenvbasic**         | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | GCC |
| **pyenvopt**           | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | GCC |
| **pyenvoptmarch**      | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | GCC |
| **pyenvoptmarchbolt**  | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | GCC |
| **uv**                 | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚úÖ | **Clang** |

```sh
docker run --rm -it my-python-image:latest bash
$ python3 -m sysconfig | grep PYTHON_CFLAGS
```

---

### Tableau de r√©sultats

| **Image** | **temps de build** | **taille Mo** | **CPU %** | **RAM Mo** | **t√¢ches / min** | **CPU / t√¢che** | **RAM / t√¢che** |
|---|---|---|---|---|---|---|---|
| **debian** | 16 s | 121 | 19,7 | 911 | 563,4 | 1,16 E-3 | 53,9 ko |
| **official** | 7 s | 124 | 27,1 | 888 | 567,6 | 1,5 E-3 | 52,1 ko |
| **pyenvbasic** | 236 (3:55) | 388 | 32,9 | 870 | 558,5 | 1,9 E-3 | 51,9 ko |
| **pyenvopt** | 1297 (21:37) | 449 | 24,3 | 886 | 572,03 | 1,41 E-3 | 51,6 ko |
| **pyenvoptmarch** | 1359 (22:39) | 450 | 23,5 | 900 | 572,06 | 1,37 E-3 | 51,6 ko |
| **pyenvoptmarchbolt** | 1562 (26:03) | 500 | 24,2 | 925 | 569,2 | 1,42 E-3 | 54,1 ko |
| **uv** | 15 s | 227 | 20,5 | 974 | 577,4 | 1,18 E-3 | 56,2 ko |

Attention :
- r√©sultats collect√©s sur un essai
- fait sur une architecture (i7-6600U CPU @ 2.60GHz, 4 coeurs)
- relatifs √† l'application de test

---

### Comparaison relative des r√©sultats

![](media/radar_chart.png)

---

## Conclusions

- ‚ö†Ô∏è les r√©sultats d'un benchmark sont contextuels √† l'application et l'infrastructure
- ‚ö†Ô∏è profilez avant d'optimiser
* importance de la t√©l√©m√©trie pour comparer avant / apr√®s
* stack de monitoring syst√®me : cAdvisor + prometheus + grafana
* les options de compilation de l'interpr√©teur `python` ont un impact sur le CPU
* üíôüíõ [uv](https://github.com/astral-sh/uv) ([python-build-standalone](https://github.com/astral-sh/python-build-standalone)) : en local ou dans un conteneur

---

## Merci !

- vos questions
- vos retours via openfeedback

![width:300px](media/openfeedback_qrcode.svg)
