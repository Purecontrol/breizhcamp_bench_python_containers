---
marp: true
theme: gaia

style: |
  img[alt~="center"] {
    display: block;
    margin: 0 auto;
  }
  section.center table {
    margin-left: auto;
    margin-right: auto;
  }
  section {
    font-size: 32px
  }
  section.lead h1 {
    font-size: 100px
  }
---


<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
<script>
  // https://connaissances.fournier38.fr/entry/Utiliser%20les%20graphs%20Mermaid%20dans%20le%20Markdown
  // Replaces <pre class="mermaid"> blocks with <img> blocks, to make mermaid render properly.
  // Preserves classes and styling so they can be used to fix sizing if necessary.

  mermaid.initialize({ startOnLoad: false });

  window.addEventListener('load', async function () {
    const mermaidEls = document.querySelectorAll('pre.mermaid');

    for (const el of mermaidEls) {
      const { svg } = await mermaid.render('asd', el.textContent);

      const img = document.createElement('img');
      img.setAttribute('src', `data:image/svg+xml;base64,${btoa(svg)}`);
      img.setAttribute('class', el.getAttribute('class'));
      img.setAttribute('style', el.getAttribute('style') || '');

      el.parentNode.replaceChild(img, el);
    }
  });
</script>

<!-- _class: lead -->
# Conteneurisation de Python
Chute de performances et investigations

<!--
_footer: "SÃ©bastien Baguet, Gaston Gary, Luc Sorel-Giffo - BreizhCamp - 27 juin 2025"
 -->

---

## Qui sommes-nous ?

* SÃ©bastien Baguet : devOps [Purecontrol](https://www.purecontrol.com/)
* Gaston Gary : dev [Purecontrol](https://www.purecontrol.com/)
* Luc Sorel-Giffo : lead dev [See you sun](https://seeyousun.fr/)
  - ex-Purecontrol ðŸ«¶
  - co-animation [Python Rennes](https://www.meetup.com/fr-FR/python-rennes/) ðŸ””
  - [@lucsorelgiffo@floss.social](https://floss.social/@lucsorelgiffo)

---

### SÃ©bastien Baguet

- **Infra lead** chez **Purecontrol**.
- spÃ©cialisÃ© dans **lâ€™infrastructure open source**, **lâ€™automatisation** et la **scalabilitÃ©** des systÃ¨mes.
- Ancien responsable infrastructure chez **ARIADNEXT by IDNow**.
- **Direction des projets R&D** en Big Data et en machine learning.
- Expertises en **bas niveau** (embarquÃ©, Ã©lectronique, rÃ©paration), aux applicatifs **Linux**, en passant par le **kernel**. 
- IntÃ©rÃªt pour **lâ€™impact environnemental** des technologies.

---

### Gaston Gary 

- dÃ©veloppeur Python depuis 3 ans chez **Purecontrol**
- Responsable rÃ©cupÃ©ration de **donnÃ©es externes** en tout genre: *MÃ©teo, puissances actives, relevÃ©s manuels d'exploitants ...*
- interconnexions Ã  des APIs
- Maintenance d'un des services de calcul

---
### Purecontrol

![width:1000px](media/fonctionnement_Purecontrol_schÃ©ma_FR.png)

<!-- Purecontrol est une sociÃ©tÃ© Rennaise, qui propose une solution de contrÃ´le-commande basÃ©e sur lâ€™intelligence artificielle ; On pilote en temps rÃ©el les procÃ©dÃ©s industriels liÃ©s Ã  lâ€™eau et Ã  lâ€™Ã©nergie pour rÃ©duire simultanÃ©ment la consommation, les coÃ»ts dâ€™exploitation et les Ã©missions de COâ‚‚. -->

---

## Applicatif mÃ©tier local-processing

(titre alternatif : Une antiquitÃ© bien dynamique)

- traitement et agrÃ©gation de **sÃ©ries temporelles**
- donnÃ©es synthÃ©tiques utilisÃ©es par d'autres briques mÃ©tier
- **50 000+ tÃ¢ches par minute**
- en temps rÃ©el
- impÃ©ratif : **ne pas accumuler de retard**

---

![](media/archi.drawio.svg)

---

- **MainService**
  - **Thread**: soumission des tÃ¢ches Ã  ProcessPoolexecutor 
  - **boucle infinie**
    - monitoring
    - update tasks output status

- **Worker**
  - traitement **unitaire** d'une tache
  - **rÃ©cupÃ©ration** des donnÃ©es temporelles en entrÃ©e
  - **transformation**
  - **Ã©criture** de la sÃ©rie temporelle en output
<!-- 
-> parallÃ©lisme +++, IO rÃ©seau ++, CPU + (traitement des donnÃ©es) -->
---

### DÃ©ploiement old school

- interprÃ©teur python de la VM
- git pull (Ã  la main en SSH)
- installation des dÃ©pendances sans **.venv/**
- redÃ©marrage ðŸ¤ž

![bg right](media/vm-museum.png)

---

### Conteneurisation Docker

```dockerfile
ARG PYTHON_VERSION
FROM python:{PYTHON_VERSION}-slim
# installation des dÃ©pendances
# copie des sources
# lancement de l'application
...
```

Avantages classiques d'une image :
- isolation et maitrise du binaire python + dÃ©pendances + code source
- exÃ©cution iso dev / tests / prod
- dÃ©ploiement : rapide, automatisable, serein

On en profite pour passer de 3.8 Ã  3.12 ðŸ˜

---

### Oui mais... perte de performance de 30% ! 

![bg right](media/futur-c-etait-mieux-avant.jpg)

- **diminution** du nombre de tÃ¢ches calculÃ©es chaque minute de **30%**
- accumulation rapide de **retard**
- optimisation dÃ©gradÃ©e des pilotages

---

### ðŸ¤” Est-ce l'effet de :

- la conteneurisation et l'allocation de ressources (CPU / RAM, overhead rÃ©seau) ?
* la dockerisation (comportement des binaires) ?
* la montÃ©e de version de Python ?

---

## Quels sont les points d'optimisation d'un service numÃ©rique python ?
- algorithmie
- architecture
- optimisation du runtime
---

### Algorithmie - 1

```python
cursor.execute(t"SELECT * FROM tasks LIMIT 100")
tasks = []
for record in cursor:
  tasks.append(Task.from_db_record(record))
execute_tasks(tasks)
```

```python
tasks = [
  Task.from_db_record(record)
  for record in cursor
] # le corps de la comprÃ©hension est exÃ©cutÃ© "d'un coup"
```

```python
execute_tasks(
  Task.from_db_record(record) for record in cursor
) # gÃ©nÃ©rateur streamant les tÃ¢ches
```

---

### Algorithmie - 2

- Python est un langage interprÃ©tÃ© ðŸŒ
* facilite l'encapsulation de binaires pour les traitements CPU âš¡
  - numpy, pandas, polars
  - Tensorflow, pytorch, jax

---

### Architecture

- multithreading ou asyncio pour parallÃ©liser les opÃ©rations IO
  * âš ï¸ au `global interpreter lock`
  * dÃ©sactivable dans la 3.14
* multiprocessing pour les opÃ©rations CPU
* tenir compte des coÃ»ts de crÃ©ation des IO (connexions bdd, threads, process) : utiliser des pools

---

### Optimisation de l'exÃ©cution - 1

```python
def transfer_money(amount: float, account):
  """ Adds a positive amount of money to the given account """
  assert is_a_valid_amount(amount)
  account.add(amount)
```

`python -O mon_script.py` supprime (voir la doc [cmdoption-O](https://docs.python.org/3/using/cmdline.html#cmdoption-O)) :
  - `-O` : les assertions, les blocs `if __debug__:`
  - `-OO` : les docstrings aussi

-> Ã©viter d'exprimer les vÃ©rifications mÃ©tier avec des `assert`

---

### Optimisation de l'exÃ©cution - 2

ðŸ§ª Just-in-time compiler (voir [whatsnew313-jit-compiler](https://docs.python.org/3/whatsnew/3.13.html#whatsnew313-jit-compiler)) :
- modification du bytecode au fil de l'exÃ©cution du programme
* additionner des entiers `!=` additionner des dÃ©cimaux
* ðŸ”Ž l'interprÃ©teur doit avoir Ã©tÃ© compilÃ© avec cette option d'exÃ©cution

---

### Optimisation du runtime python

DiffÃ©rentes optimisations durant les phases de compilations :

![center](./media/optimizations.drawio.svg)

Voir les options de compilation du runtime :

```sh
python3 -m sysconfig | grep CONFIG_ARGS
```

<!-- Seb
Compiler level optimisation

-O3 -> va optimiser fichier par fichier
-march=native -> SÃ©lÃ©ction de l'architecture courante comme cible
/!\ pas compatible avec un CPU qui n'aurait pas les instructions
Voir ici pour les subset https://gcc.gnu.org/onlinedocs/gcc/x86-Options.html

Profile Guided optimization
Compilation instrumentÃ© -> Execution -> Recompilation optimisÃ©

Inlining, rÃ©organisation des blocs, optimisation des boucles, etc.

Link Time Optimization
Optimisation multi fichier .o

Analyse statique du programme entier

Post Link Optimization
Compilation normale -> Profilage (optionnel) -> Optimisation du binaire

RÃ©arrangement des fonctions/blocs (layout), ICF, optimisation des tables de saut, etc.
Optimisation cache


Flags

https://docs.python.org/3/using/configure.html#performance-options

 -->

---

<!-- 
### Comparaison de Dockerfiles officiels

- https://hub.docker.com/_/python/
  - https://github.com/docker-library/python/blob/14b61451ec7c172cf1d43d8e7859335459fcd344/3.11/slim-bookworm/Dockerfile#L72-L95

---

### Installation personnalisÃ©e avec pyenv LUC

voir :
- https://github.com/pyenv/pyenv/blob/master/plugins/python-build/README.md#special-environment-variables : CONFIGURE_OPTS
- https://github.com/pyenv/pyenv/blob/master/plugins/python-build/README.md#building-for-maximum-performance : --enable-optimizations

--- -->

### Attention aux options de compilation

Si les flags de compilation Ã©noncÃ©s plus haut peuvent sembler optimaux,
Il y a  tout de mÃªme quelques point important Ã  garder en tÃªte ...

---

###  ils introduisent des **dÃ©pendances invisibles** Ã  lâ€™architecture CPU

par exemple pour -march=native
- On **compile** lâ€™interprÃ©teur Python **spÃ©cifiquement** pour lâ€™architecture du **CPU**.
- RÃ©sultat : lâ€™image **ne fonctionne plus** si on la lance sur une autre architecture (ex: `build` sur AMD â†’ `run` sur INTEL)

Il est donc **crucial** dâ€™avoir la **mÃªme architecture CPU** entre le `build` et le `run`

Sinon âžœ crash, `illegal instruction`.


<!-- 
- Nous l'avons dÃ©couvert Ã  la dur, notre runner gitlab Ã©tait hÃ©bergÃ© sur un noeud proxmox sous cpu **Intel Xeon Platinium**, alors que notre **vm de Production** Ã©tait sur un noeud proxmox sous cpu **AMD EPYC**. -->

---

## Benchmark des binaires python via des conteneurs

- applicatif "test" (architecture et opÃ©rations similaires Ã  l'application) tournant 30 minutes
- temps de crÃ©ation & taille de chaque image Docker (7 images)
- mÃ©triques "systÃ¨me" : consommations CPU & RAM
- mÃ©triques mÃ©tier :  nb de tÃ¢ches rÃ©alisÃ©es
- mÃ©triques hybrides : CPU / tÃ¢che, RAM / tÃ¢che

---

### Collecte des mÃ©triques systÃ¨me

<pre class="mermaid">
  flowchart LR
    bench -..->| mesures CPU et RAM | cAdvisor
    subgraph monitoring
      cAdvisor -..->| scrapping / 5s | prometheus
      prometheus -..->| dashboard | grafana
    end
</pre>

<!-- Pour suivre en temps rÃ©el :

- l'usage MÃ©moire
- l'usage CPU
- l'usage I/O disque & rÃ©seau

IdÃ©al pour dÃ©tecter une **saturation systÃ¨me**


Exploiter les **logs et mÃ©triques** pour suivre :

- Nombre de tÃ¢ches traitÃ©es par minute
- DurÃ©e moyenne de traitement par tÃ¢che
- Les tÃ¢ches en echecs.

Permet d'avoir une vision fonctionnelle de la performance de notre application.

Utiliser un profiler comme `kcachegrind` sur les rÃ©sultats de Cprofile.

Pour visualiser :

- Fonctions les plus coÃ»teuses
- Appels imbriquÃ©s
- Consommation CPU par bloc de code

En comparant avant et aprÃ¨s, cela pourrait permettre d'identifier un endroit ou l'on passe plus de temps, responsable d'une perte de performance.

```python
python -m cProfile -o prof.out my_app.py && pyprof2calltree -i prof.out -o callgrind.out && kcachegrind callgrind.out
```
 -->
---

### prÃ©sentation du bench et des diffÃ©rentes images LUC todo reformuler

On a compilÃ© et mesurÃ© le temps de crÃ©ation des conteneurs.

une stack docker compose avec:
- cadvisor
- prometheus
- grafana

---

Maquette de notre applicatif python:
- Cpu heavy
- IO
- en continue sur 30 minutes. 

<!-- Cadvisor gÃ©nÃ¨re des mÃ©triques sur les conteneurs, prometheus les scraps et les stocks, grafana nous permets de les visualiser.  -->
---

### Comparatif de nos images

<!-- style: table{font-size:.55em} -->


| Image            | `--enable-optimizations` | `--with-lto` | `--enable-bolt` | `-march = native` | `-mtune = native` | **Compilateur** |
|------------------------|:---------------------------------:|:------------:|:---------------:|:-------------------:|:-------------------:|:---------------:|
| **debian**             | âœ˜ | âœ˜ | âœ˜ | âœ˜ | âœ˜ | **GCC** |
| **official (slim)**    | âœ”ï¸Ž | âœ”ï¸Ž | âœ˜ | âœ˜ | âœ˜ | **GCC** |
| **pyenvbasic**         | âœ˜ | âœ˜ | âœ˜ | âœ˜ | âœ˜ | **GCC** |
| **pyenvopt**           | âœ”ï¸Ž | âœ”ï¸Ž | âœ˜ | âœ˜ | âœ˜ | **GCC** |
| **pyenvoptmarch**      | âœ”ï¸Ž | âœ”ï¸Ž | âœ˜ | âœ”ï¸Ž | âœ”ï¸Ž | **GCC** |
| **pyenvoptmarchbolt**  | âœ”ï¸Ž | âœ”ï¸Ž | âœ”ï¸Ž | âœ”ï¸Ž | âœ”ï¸Ž | **GCC** |
| **uv**  | âœ”ï¸Ž | âœ”ï¸Ž | âœ”ï¸Ž | âœ˜ | âœ˜ | **Clang** |

---

### rÃ©sultats #LUC


- nombre de calculs faits chaque minute
- durÃ©e moyenne d'un calcul
- CPU et RAM mobilisÃ©e

---

## Conclusions

- python est un langage interprÃ©tÃ©, son interprÃ©teur est compilÃ© ; des options de compilations existent (https://docs.python.org/3/using/configure.html#general-options, https://docs.python.org/3/using/configure.html#performance-options)

- (https://stackoverflow.com/questions/10192758/how-to-get-the-list-of-options-that-python-was-compiled-with)

```sh
# configuration de python
python3 -m sysconfig
python3 -m sysconfig | grep CONFIG_ARGS
```

- pyenv installe depuis les sources, configuration du build avec des drapeaux ou des variables d'environnement
- python-build-standalone (utilisÃ© par uv) produit des binaires optimisÃ©s avec `--enable-optimizations` (https://github.com/astral-sh/python-build-standalone/blob/main/cpython-unix/build-cpython.sh#L472), mais d'autres drapeaux d'optimisation spÃ©cifique (Ã  l'architecture du CPU) ne sont pas utilisÃ©s

---

## Merci !

Vos questions

Vos retours via openfeedback :

![width:400px](media/openfeedback_qrcode.svg)
