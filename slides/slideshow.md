---
marp: true
theme: gaia

style: |
  img[alt~="center"] {
    display: block;
    margin: 0 auto;
  }
  section.center table {
    margin-left: auto;
    margin-right: auto;
  }
  section {
    font-size: 32px
  }
  section.lead h1 {
    font-size: 100px
  }
---
<!-- _class: lead -->
# Conteneurisation de Python
Chute de performances et investigations

<!--
_footer: "S√©bastien Baguet, Gaston Gary, Luc Sorel-Giffo - BreizhCamp - 27 juin 2025"
 -->

---

## Qui sommes-nous ?

* S√©bastien Baguet : devOps [Purecontrol](https://www.purecontrol.com/)
* Gaston Gary : dev [Purecontrol](https://www.purecontrol.com/)
* Luc Sorel-Giffo : lead dev [See you sun](https://seeyousun.fr/)
  - ex-Purecontrol ü´∂
  - co-animation [Python Rennes](https://www.meetup.com/fr-FR/python-rennes/) üîî
  - [@lucsorelgiffo@floss.social](https://floss.social/@lucsorelgiffo)

---

### S√©bastien Baguet

- **Infra lead** chez **Purecontrol**.
- sp√©cialis√© dans **l‚Äôinfrastructure open source**, **l‚Äôautomatisation** et la **scalabilit√©** des syst√®mes.
- Ancien responsable infrastructure chez **ARIADNEXT by IDNow**.
- **Direction des projets R&D** en Big Data et en machine learning.
- Expertises en **bas niveau** (embarqu√©, √©lectronique, r√©paration), aux applicatifs **Linux**, en passant par le **kernel**. 
- Int√©r√™t pour **l‚Äôimpact environnemental** des technologies.

---

### Gaston Gary 

- d√©veloppeur Python depuis 3 ans chez **Purecontrol**
- Responsable de la r√©cup√©ration de **donn√©es externes** en tout genre: *M√©teo, puissances actives, relev√©s manuels d'exploitants ...*
- interconnexions √† des APIs
- Responsable d'un service de calcul de timeseries pr√©nomm√© ...

#TODO schema marketing et quick presentation metier purecontrol

---

## Applicatif m√©tier local-processing

(titre alternatif : Une antiquit√© bien dynamique)

- traitement et agr√©gation de **s√©ries temporelles**
- donn√©es synth√©tiques utilis√©es par d'autres briques m√©tier
- **50 000+ t√¢ches par minute**
- en temps r√©el
- imp√©ratif : **ne pas accumuler de retard**

---

![bg right;width:850px](media/archi.drawio.svg)

---

### key points architecture

- **MainService**
  - **Thread**: soumission des t√¢ches √† ProcessPoolexecutor 
  - **boucle infinie**
    - monitoring
    - update tasks output status

- **Worker**
  - traitement **unitaire** d'une tache
  - **r√©cup√©ration** des donn√©es temporelles en entr√©e
  - **transformation**
  - **√©criture** de la s√©rie temporelle en output

-> parall√©lisme +++, IO r√©seau ++, CPU + (traitement des donn√©es)

---

### D√©ploiement old school

- interpr√©teur python de la VM
- git pull (√† la main en SSH)
- installation des d√©pendances sans **.venv/**
- red√©marrage ü§û

![bg right](media/vm-museum.png)

---

### Conteneurisation Docker

```dockerfile
ARG PYTHON_VERSION
FROM python:{PYTHON_VERSION}-slim
# installation des d√©pendances
# copie des sources
# lancement de l'application
...
```

Avantages classiques d'une image :
- isolation et maitrise du binaire python + d√©pendances + code source
- ex√©cution iso dev / tests / prod
- d√©ploiement : rapide, automatisable, serein

On en profite pour passer de 3.8 √† 3.12 üòÅ

---

### Oui mais... perte de performance de 30% ! 

![bg right](media/futur-c-etait-mieux-avant.jpg)

- **diminution** du nombre de t√¢ches calcul√©es chaque minute de **30%**
- accumulation rapide de **retard**
- optimisation d√©grad√©e des pilotages

---

### ü§î Est-ce l'effet de :

- la conteneurisation et l'allocation de ressources (CPU / RAM, overhead r√©seau) ?
* la dockerisation (comportement des binaires) ?
* la mont√©e de version de Python ?

---

## Quels sont les points d'optimisation d'un service num√©rique python ?
- algorithmie
- architecture
- optimisation du runtime
---

### Algorithmie - 1

```python
cursor.execute(t"SELECT * FROM tasks LIMIT 100")
tasks = []
for record in cursor:
  tasks.append(Task.from_db_record(record))
execute_tasks(tasks)
```

```python
tasks = [
  Task.from_db_record(record)
  for record in cursor
] # le corps de la compr√©hension est ex√©cut√© "d'un coup"
```

```python
execute_tasks(
  Task.from_db_record(record) for record in cursor
) # g√©n√©rateur streamant les t√¢ches
```

---

### Algorithmie - 2

- Python est un langage interpr√©t√© üêå
* facilite l'encapsulation de binaires pour les traitements CPU ‚ö°
  - numpy, pandas, polars
  - Tensorflow, pytorch, jax

---

### Architecture

- multithreading ou asyncio pour parall√©liser les op√©rations IO
  * ‚ö†Ô∏è au `global interpreter lock`
  * d√©sactivable dans la 3.14
* multiprocessing pour les op√©rations CPU

---

### Optimisation de l'ex√©cution - 1

```python
def transfer_money(amount: float, account):
  """ Adds a positive amount of money to the given account """
  assert is_a_valid_amount(amount)
  account.add(amount)
```

`python -O mon_script.py` supprime :
  - `-O` : les assertions, les blocs `if __debug__:`
  - `-OO` : les docstrings aussi

√âviter d'exprimer les v√©rifications m√©tier avec des `assert`
- ignor√©es en mode optimize (voir la doc [cmdoption-O](https://docs.python.org/3/using/cmdline.html#cmdoption-O))
- try-except : tout devient `AssertionError`

---

### Optimisation de l'ex√©cution - 2

üß™ Just-in-time compiler (3.13+) :
- modification du bytecode au fil de l'ex√©cution du programme
* additionner des entiers `!=` additionner des d√©cimaux
* üîé l'interpr√©teur doit avoir √©t√© compil√© avec cette option d'ex√©cution

Voir [whatsnew313-jit-compiler](https://docs.python.org/3/whatsnew/3.13.html#whatsnew313-jit-compiler)

---

### Optimisation du runtime python

- Diff√©rentes optimisations durant les phases de compilations

![center](./media/optimizations.drawio.svg)


- Pour visualiser les options du runtime
  - `python3 -m sysconfig | grep CONFIG_ARGS`


<!-- Seb
Compiler level optimisation

-O3 -> va optimiser fichier par fichier
-march=native -> S√©l√©ction de l'architecture courante comme cible
/!\ pas compatible avec un CPU qui n'aurait pas les instructions
Voir ici pour les subset https://gcc.gnu.org/onlinedocs/gcc/x86-Options.html

Profile Guided optimization
Compilation instrument√© -> Execution -> Recompilation optimis√©

Inlining, r√©organisation des blocs, optimisation des boucles, etc.

Link Time Optimization
Optimisation multi fichier .o

Analyse statique du programme entier

Post Link Optimization
Compilation normale -> Profilage (optionnel) -> Optimisation du binaire

R√©arrangement des fonctions/blocs (layout), ICF, optimisation des tables de saut, etc.
Optimisation cache


Flags

https://docs.python.org/3/using/configure.html#performance-options

 -->

#TODO slide recap option compile de chaque image GG

---
<!-- 
### Comparaison de Dockerfiles officiels

- https://hub.docker.com/_/python/
  - https://github.com/docker-library/python/blob/14b61451ec7c172cf1d43d8e7859335459fcd344/3.11/slim-bookworm/Dockerfile#L72-L95

---

### Installation personnalis√©e avec pyenv LUC

voir :
- https://github.com/pyenv/pyenv/blob/master/plugins/python-build/README.md#special-environment-variables : CONFIGURE_OPTS
- https://github.com/pyenv/pyenv/blob/master/plugins/python-build/README.md#building-for-maximum-performance : --enable-optimizations

--- -->

### Attention aux options de compilation

Si les flags de compilation √©nonc√©s plus haut peuvent sembler optimaux,
Il y a  tout de m√™me quelques point important √† garder en t√™te ...

---

###  ils introduisent des **d√©pendances invisibles** √† l‚Äôarchitecture CPU

par exemple pour -march=native
- On **compile** l‚Äôinterpr√©teur Python **sp√©cifiquement** pour l‚Äôarchitecture du **CPU**.
- R√©sultat : l‚Äôimage **ne fonctionne plus** si on la lance sur une autre architecture (ex: `build` sur AMD ‚Üí `run` sur INTEL)

Il est donc **crucial** d‚Äôavoir la **m√™me architecture CPU** entre le `build` et le `run`

Sinon ‚ûú crash, `illegal instruction`.


<!-- 
- Nous l'avons d√©couvert √† la dur, notre runner gitlab √©tait h√©berg√© sur un noeud proxmox sous cpu **Intel Xeon Platinium**, alors que notre **vm de Production** √©tait sur un noeud proxmox sous cpu **AMD EPYC**. -->

---

## Benchmarking : par o√π commencer ? 

**Comment enqu√™ter sur les perfs d‚Äôun conteneur ?**

---

## Outils

- `cadvisor`
- M√©triques et logs niveau applicatif
- Profilage du code

<!-- Pour suivre en temps r√©el :

- l'usage M√©moire
- l'usage CPU
- l'usage I/O disque & r√©seau

Id√©al pour d√©tecter une **saturation syst√®me un √©ventuel bottleneck**


Exploiter les **logs et m√©triques** pour suivre :

- Nombre de t√¢ches trait√©es par minute
- Dur√©e moyenne de traitement par t√¢che
- Les t√¢ches en echecs.

Permet d'avoir une vision fonctionnelle de la performance de notre application.

Utiliser un profiler comme `kcachegrind` sur les r√©sultats de Cprofile.

Pour visualiser :

- Fonctions les plus co√ªteuses
- Appels imbriqu√©s
- Consommation CPU par bloc de code

En comparant avant et apr√®s, cela pourrait permettre d'identifier un endroit ou l'on passe plus de temps, responsable d'une perte de performance.

```python
python -m cProfile -o prof.out my_app.py && pyprof2calltree -i prof.out -o callgrind.out && kcachegrind callgrind.out
```
 -->
---

### pr√©sentation du bench et des diff√©rentes images LUC todo reformuler

On a compil√© et mesur√© le temps de cr√©ation des conteneurs.

une stack docker compose avec:
- cadvisor
- prometheus
- grafana

---

Maquette de notre applicatif python:
- Cpu heavy
- IO
- en continue sur 30 minutes. 

<!-- Cadvisor g√©n√®re des m√©triques sur les conteneurs, prometheus les scraps et les stocks, grafana nous permets de les visualiser.  -->
---

#TODO GASTON tableau r√©cap des flags de compile de chaque Dockerfile

---

### r√©sultats #LUC


- nombre de calculs faits chaque minute
- dur√©e moyenne d'un calcul
- CPU et RAM mobilis√©e

---

## Conclusions

- python est un langage interpr√©t√©, son interpr√©teur est compil√© ; des options de compilations existent (https://docs.python.org/3/using/configure.html#general-options, https://docs.python.org/3/using/configure.html#performance-options)

- (https://stackoverflow.com/questions/10192758/how-to-get-the-list-of-options-that-python-was-compiled-with)

```sh
# configuration de python
python3 -m sysconfig
python3 -m sysconfig | grep CONFIG_ARGS
```

- pyenv installe depuis les sources, configuration du build avec des drapeaux ou des variables d'environnement
- python-build-standalone (utilis√© par uv) produit des binaires optimis√©s avec `--enable-optimizations` (https://github.com/astral-sh/python-build-standalone/blob/main/cpython-unix/build-cpython.sh#L472), mais d'autres drapeaux d'optimisation sp√©cifique (√† l'architecture du CPU) ne sont pas utilis√©s

---

### Bonne pratique

 **Construisez l‚Äôimage une fois**, puis :

- Stockez-la dans une **registry**
- **R√©utilisez-la** sur toutes les machines compatibles, et toutes les applications python compatible.

Ne reconstruisez pas l‚Äôimage inutilement √† chaque run.

![bg right](media/buildworkflow.drawio.svg)

---

## Merci !

Vos questions

Vos retours via openfeedback :

![width:400px](media/openfeedback_qrcode.svg)
